# ğŸ§  Backend Lumina (API & Crawler)

O nÃºcleo de processamento do Lumina, responsÃ¡vel pela coleta de notÃ­cias, armazenamento vetorial, processamento de IA e gerenciamento de conteÃºdo via Painel Administrativo.

# ğŸ“‹ Requisitos PrÃ©vios

Certifique-se de que os seguintes requisitos estÃ£o instalados no seu sistema:

1. **Python**: VersÃ£o 3.10 ou superior.
2. **pip**: O gerenciador de pacotes do Python, que geralmente Ã© instalado junto com o Python.
3. **Navegadores(Opcional)**: Para rodar os testes de interface (E2E): eles sÃ£o relativamente pesados, por isso foram colocados no gitignore. Portanto, serÃ¡ necessÃ¡rio instalar os binÃ¡rios do Playwright (instruÃ§Ãµes abaixo).

---

## ğŸ› ï¸ ConfiguraÃ§Ã£o do Ambiente

### 1. InstalaÃ§Ã£o de DependÃªncias

Todas as bibliotecas necessÃ¡rias para o projeto estÃ£o listadas no arquivo `requirements.txt`.

Para instalÃ¡-las, abra o seu terminal no diretÃ³rio raiz do projeto e execute o comando:

```bash
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o da Chave API do Gemini

O projeto requer uma chave de API para interagir com o modelo Gemini. VocÃª precisa criar um arquivo chamado `.env` na raiz do seu projeto e adicionar sua chave nele.

O conteÃºdo do seu arquivo `.env` deve seguir este formato:

```
GOOGLE_API_KEY="SUA_CHAVE_DE_API_DO_GEMINI_AQUI"
```

* Substitua `"SUA_CHAVE_DE_API_DO_GEMINI_AQUI"` pela sua chave real.

### 3. InstalaÃ§Ã£o do Playwright (Para Testes E2E)

Se vocÃª pretende rodar os testes de interface (frontend do admin), instale os navegadores necessÃ¡rios:

```
python -m playwright install chromium
```



---

## ğŸš€ Como Rodar o Servidor

ApÃ³s instalar as dependÃªncias e configurar a chave API, vocÃª pode iniciar o servidor localmente usando Uvicorn.

Execute o seguinte comando no terminal (ainda no diretÃ³rio raiz do projeto):

```bash
uvicorn main:app --reload
```

### Detalhes do Comando

* `uvicorn`: O servidor ASGI rÃ¡pido que estamos usando.
* `main:app`: Indica ao Uvicorn para procurar a aplicaÃ§Ã£o (variÃ¡vel `app`) dentro do mÃ³dulo (`main.py`).
* `--reload`: Ativa o modo de recarga automÃ¡tica. O servidor serÃ¡ reiniciado automaticamente sempre que vocÃª salvar alteraÃ§Ãµes no seu cÃ³digo-fonte, o que Ã© Ã³timo para o desenvolvimento.

O servidor estarÃ¡ rodando `http://127.0.0.1:8000`.
- API Docs (Swagger): `http://127.0.0.1:8000/docs`
- Painel Admin: `http://127.0.0.1:8000/admin`

ip do servidor na nuvem: 152.67.59.120

## ğŸ“° Painel Administrativo (Lumina Admin)

O sistema possui uma interface web para gerenciamento das notÃ­cias coletadas.

ApÃ³s instalar as dependÃªncias e configurar a chave API, vocÃª pode iniciar o servidor localmente usando Uvicorn.

Execute o seguinte comando no terminal (dentro da pasta backend):

```bash
uvicorn main:app --reload
```

* `uvicorn`: O servidor ASGI rÃ¡pido que estamos usando.
* `main:app`: Indica ao Uvicorn para procurar a aplicaÃ§Ã£o (variÃ¡vel `app`) dentro do mÃ³dulo (`main.py`).
* `--reload`: Ativa o modo de recarga automÃ¡tica. O servidor serÃ¡ reiniciado automaticamente sempre que vocÃª salvar alteraÃ§Ãµes no seu cÃ³digo-fonte, o que Ã© Ã³timo para o desenvolvimento.

O servidor estarÃ¡ rodando em `http://127.0.0.1:8000/admin`
FaÃ§a login com a senha de administrador configurada (PadrÃ£o: admin).

**Funcionalidades**
- Dashboard Unificado: Visualiza notÃ­cias de mÃºltiplas fontes (G1 e MetrÃ³poles) em uma Ãºnica tabela.
- EstatÃ­sticas (KPIs): Cards informativos com o total de artigos coletados por fonte.
- Adicionar NotÃ­cia: Permite inserir manualmente um link de notÃ­cia para ser processado pelo Crawler.
- ExclusÃ£o: Remove artigos indesejados do banco de dados.

## ğŸ•·ï¸ Crawlers e Coleta de Dados

O sistema suporta mÃºltiplos crawlers que podem ser executados manualmente para popular o banco de dados.

**Executar Crawler do G1**

```
python -m scripts.run_crawler
```

**Executar Crawler do MetrÃ³poles**

```
python -m scripts.run_metropoles_crawler
```

**Nota:** Os crawlers salvam o estado em arquivos JSON (`crawler_state.json`) para permitir pausar e continuar a coleta posteriormente.

## âœ… Testes Automatizados

O projeto segue uma rigorosa polÃ­tica de testes, cobrindo desde a unidade atÃ© a interface do usuÃ¡rio.

1. Testes de Backend (Unidade e IntegraÃ§Ã£o)
Testam a lÃ³gica do banco de dados, crawlers e endpoints da API.

```
pytest
```

(Ignora automaticamente a pasta tests/e2e para ser mais rÃ¡pido)

2. Testes de Frontend (End-to-End / E2E)

Testam a interface do Admin simulando um usuÃ¡rio real navegando no Chrome.
**Requisito:** O servidor deve estar rodando em outro terminal (`uvicorn main:app`).

```
python -m pytest tests/e2e --browser chromium
```

Para ver o navegador abrindo na tela, adicione `--headed --slowmo 1000`.



## ğŸ“‚ Estrutura do Projeto

### Backend

A estrutura de pastas do backend foi organizada para separar as responsabilidades e facilitar a manutenÃ§Ã£o.

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ai/                 # LÃ³gica de IA (Gemini, RAG, Embeddings)
â”‚   â”œâ”€â”€ db/                 # Gerenciamento de Banco de Dados (SQLite e ChromaDB)
â”‚   â”œâ”€â”€ models/             # Modelos de Dados (Pydantic)
â”‚   â”œâ”€â”€ routers/            # Rotas da API e do Admin
â”‚   â”œâ”€â”€ services/           # LÃ³gica de NegÃ³cio (ChatService, ScrapingManager)
â”‚   â”œâ”€â”€ static/             # Arquivos CSS/JS do Admin
â”‚   â”œâ”€â”€ templates/          # Templates HTML (Jinja2) do Admin
â”‚   â””â”€â”€ webcrawler/         # MÃ³dulos de Coleta de Dados
â”‚       â”œâ”€â”€ G1/             # ImplementaÃ§Ã£o especÃ­fica G1
â”‚       â””â”€â”€ Metropoles/     # ImplementaÃ§Ã£o especÃ­fica MetrÃ³poles
â”œâ”€â”€ scripts/                # Scripts utilitÃ¡rios (Executar crawler, Debug DB)
â”œâ”€â”€ tests/                  # Testes Automatizados
â”‚   â”œâ”€â”€ e2e/                # Testes de Interface (Playwright)
â”‚   â””â”€â”€ ...                 # Testes de Unidade (Pytest)
â”œâ”€â”€ main.py                 # Ponto de entrada da aplicaÃ§Ã£o
â””â”€â”€ requirements.txt        # DependÃªncias do projeto
```

### MÃ³dulos Principais

*   **`main.py`**: Ponto de entrada do servidor FastAPI. ResponsÃ¡vel por orquestrar as rotas da API que expÃµem as funcionalidades do sistema, como a busca e sumarizaÃ§Ã£o de notÃ­cias.

*   **`run_crawler.py`**: Script dedicado para iniciar o processo de rastreamento e scraping de notÃ­cias. Ele ativa os crawlers especÃ­ficos para cada fonte de notÃ­cia.

*   **`app/webcrawler/`**: MÃ³dulo central para a coleta de dados. ContÃ©m a lÃ³gica para rastrear sites de notÃ­cias e extrair links para artigos. Ã‰ projetado de forma extensÃ­vel para suportar novas fontes.
    *   **`G1/`** e **`Metropoles/`**: SubdiretÃ³rios que contÃªm a implementaÃ§Ã£o especÃ­fica para cada portal, incluindo a extraÃ§Ã£o de links e o scraping do conteÃºdo.

*   **`app/models/`**: Define as estruturas de dados do projeto, como o modelo `Article`, que representa um artigo de notÃ­cia com seus atributos (tÃ­tulo, conteÃºdo, data, etc.).

*   **`app/db/`**: Camada de persistÃªncia de dados. Gerencia a conexÃ£o com o banco de dados SQLite (`articles.db`) e o banco de vetores (`ChromaDB`), sendo responsÃ¡vel por armazenar e consultar os artigos e seus embeddings.

*   **`app/ai/`**: MÃ³dulo de inteligÃªncia artificial. Integra-se com o Google Gemini para realizar tarefas de processamento de linguagem natural, como a sumarizaÃ§Ã£o de textos, utilizando a tÃ©cnica de RAG (Retrieval-Augmented Generation).

*   **`tests/`**: ContÃ©m os testes automatizados do projeto, garantindo a qualidade e o correto funcionamento dos componentes.
