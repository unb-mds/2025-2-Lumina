<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=49877&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Estudo: APIs e Web Crawlers | É Fake</title>
<meta name="keywords" content="">
<meta name="description" content="1. Introdução
Este documento explica os conceitos de web crawling e APIs REST, compara ferramentas populares para construir crawlers e discute os principais desafios legais e éticos associados à coleta automatizada de dados.

2. O que é Web Crawling
Web crawling é o processo automatizado de navegar por páginas web e coletar (baixar) seu conteúdo para indexação, análise ou extração de dados. Crawlers — também chamados de spiders — visitam URLs, seguem links e armazenam cópias das páginas ou extraem informações específicas.">
<meta name="author" content="">
<link rel="canonical" href="//localhost:49877/posts/apiswebcrawlers/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b8c5fe199b6ed7d82f8d796745cb75f1db5c0e80089bf3c900c156f7941e8838.css" integrity="sha256-uMX&#43;GZtu19gvjXlnRct18dtcDoAIm/PJAMFW95QeiDg=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:49877/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:49877/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:49877/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:49877/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:49877/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:49877/posts/apiswebcrawlers/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:49877/" accesskey="h" title="É Fake (Alt + H)">É Fake</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:49877/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="//localhost:49877/categories/" title="Categorias">
                    <span>Categorias</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="//localhost:49877/">Home</a>&nbsp;»&nbsp;<a href="//localhost:49877/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Estudo: APIs e Web Crawlers
    </h1>
    <div class="post-meta">

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-introdu%c3%a7%c3%a3o" aria-label="1. Introdução">1. Introdução</a></li>
                <li>
                    <a href="#2-o-que-%c3%a9-web-crawling" aria-label="2. O que é Web Crawling">2. O que é Web Crawling</a></li>
                <li>
                    <a href="#3-como-funcionam-os-web-crawlers-t%c3%a9cnica" aria-label="3. Como funcionam os Web Crawlers (técnica)">3. Como funcionam os Web Crawlers (técnica)</a></li>
                <li>
                    <a href="#4-principais-ferramentas-para-cria%c3%a7%c3%a3o-de-crawlers--levantamento-e-compara%c3%a7%c3%a3o" aria-label="4. Principais ferramentas para criação de crawlers — levantamento e comparação">4. Principais ferramentas para criação de crawlers — levantamento e comparação</a></li>
                <li>
                    <a href="#5-o-que-s%c3%a3o-apis-rest-e-como-funcionam" aria-label="5. O que são APIs REST e como funcionam">5. O que são APIs REST e como funcionam</a><ul>
                        
                <li>
                    <a href="#conceito" aria-label="Conceito">Conceito</a></li>
                <li>
                    <a href="#princ%c3%adpios-chave-do-rest" aria-label="Princípios chave do REST">Princípios chave do REST</a></li>
                <li>
                    <a href="#elementos-pr%c3%a1ticos" aria-label="Elementos práticos">Elementos práticos</a></li>
                <li>
                    <a href="#exemplo-simples-curl" aria-label="Exemplo simples (curl)">Exemplo simples (curl)</a></li></ul>
                </li>
                <li>
                    <a href="#6-apis-p%c3%bablicas-%c3%bateis" aria-label="6. APIs públicas úteis">6. APIs públicas úteis</a></li>
                <li>
                    <a href="#7-desafios-legais-e-%c3%a9ticos-na-coleta-de-dados" aria-label="7. Desafios legais e éticos na coleta de dados">7. Desafios legais e éticos na coleta de dados</a><ul>
                        
                <li>
                    <a href="#principais-aspectos-legais" aria-label="Principais aspectos legais">Principais aspectos legais</a></li>
                <li>
                    <a href="#quest%c3%b5es-%c3%a9ticas" aria-label="Questões éticas">Questões éticas</a></li></ul>
                </li>
                <li>
                    <a href="#8-boas-pr%c3%a1ticas-ao-coletar-dados-crawling-e-via-apis" aria-label="8. Boas práticas ao coletar dados (crawling e via APIs)">8. Boas práticas ao coletar dados (crawling e via APIs)</a></li>
                <li>
                    <a href="#9-conclus%c3%a3o" aria-label="9. Conclusão">9. Conclusão</a></li>
                <li>
                    <a href="#10-refer%c3%aancias" aria-label="10. Referências">10. Referências</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="1-introdução">1. Introdução<a hidden class="anchor" aria-hidden="true" href="#1-introdução">#</a></h2>
<p>Este documento explica os conceitos de <strong>web crawling</strong> e <strong>APIs REST</strong>, compara ferramentas populares para construir crawlers e discute os principais desafios legais e éticos associados à coleta automatizada de dados.</p>
<hr>
<h2 id="2-o-que-é-web-crawling">2. O que é Web Crawling<a hidden class="anchor" aria-hidden="true" href="#2-o-que-é-web-crawling">#</a></h2>
<p><strong>Web crawling</strong> é o processo automatizado de navegar por páginas web e coletar (baixar) seu conteúdo para indexação, análise ou extração de dados. Crawlers — também chamados de spiders — visitam URLs, seguem links e armazenam cópias das páginas ou extraem informações específicas.</p>
<p><strong>Quando usar crawling vs scraping vs APIs:</strong></p>
<ul>
<li><em>Crawling</em> normalmente refere-se ao ato de descobrir páginas (seguir links) em grande escala.</li>
<li><em>Scraping</em> é a extração de dados de páginas individuais (parsing HTML, extrair campos).</li>
<li><em>APIs</em> são interfaces fornecidas pelos serviços para acesso estruturado — sempre que disponível, preferir API em vez de scraping.</li>
</ul>
<hr>
<h2 id="3-como-funcionam-os-web-crawlers-técnica">3. Como funcionam os Web Crawlers (técnica)<a hidden class="anchor" aria-hidden="true" href="#3-como-funcionam-os-web-crawlers-técnica">#</a></h2>
<p>Fluxo básico de um crawler:</p>
<ol>
<li><strong>Seed list (lista inicial):</strong> começa com um conjunto de URLs.</li>
<li><strong>Fetch (requisição):</strong> faz requisições HTTP das páginas.</li>
<li><strong>Parse:</strong> analisa o HTML para extrair links e conteúdo relevante.</li>
<li><strong>URL queue (fila):</strong> adiciona novos links para visitar (com políticas de prioridade).</li>
<li><strong>Storage/indexação:</strong> salva páginas ou extrai e armazena campos em banco de dados.</li>
<li><strong>Políticas:</strong> politeness (intervalos entre requisições), politeness por host, limites de profundidade, tratamento de duplicatas.</li>
</ol>
<p>Componentes técnicos importantes:</p>
<ul>
<li><strong>User-agent</strong> — identifica o bot; deve cumprir regras indicadas em <code>robots.txt</code> quando aplicável.</li>
<li><strong>robots.txt</strong> — protocolo de exclusão usado por sites para indicar quais caminhos os crawlers podem acessar.</li>
<li><strong>Sitemaps</strong> — arquivos que listam URLs que o site deseja que sejam indexados.</li>
<li><strong>Renderização JavaScript</strong> — muitos sites modernos carregam conteúdo via JS; é preciso renderizar (headless browser) ou usar ferramentas que executem JS.</li>
</ul>
<hr>
<h2 id="4-principais-ferramentas-para-criação-de-crawlers--levantamento-e-comparação">4. Principais ferramentas para criação de crawlers — levantamento e comparação<a hidden class="anchor" aria-hidden="true" href="#4-principais-ferramentas-para-criação-de-crawlers--levantamento-e-comparação">#</a></h2>
<p>Abaixo há uma visão geral das ferramentas mais usadas (foco em 2024–2025):</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Ferramenta</th>
          <th style="text-align: left">Tipo</th>
          <th style="text-align: left">Linguagem</th>
          <th style="text-align: left">Quando usar</th>
          <th style="text-align: left">Prós</th>
          <th style="text-align: left">Contras</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Scrapy</strong></td>
          <td style="text-align: left">Framework crawler</td>
          <td style="text-align: left">Python</td>
          <td style="text-align: left">Crawling/scraping em larga escala, pipelines</td>
          <td style="text-align: left">Projetado para scraping, alto desempenho, extensível, comunidade ativa.</td>
          <td style="text-align: left">Curva de aprendizado; não executa JS por padrão.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>BeautifulSoup</strong></td>
          <td style="text-align: left">Parser HTML</td>
          <td style="text-align: left">Python</td>
          <td style="text-align: left">Extração simples de páginas estáticas</td>
          <td style="text-align: left">Fácil para parsing e protótipos.</td>
          <td style="text-align: left">Não faz requests paralelos nem renderiza JS (usado junto com requests).</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Selenium</strong></td>
          <td style="text-align: left">Browser automation</td>
          <td style="text-align: left">Multi (bindings em Python, JS)</td>
          <td style="text-align: left">Sites com JS complexo; automação de navegador</td>
          <td style="text-align: left">Executa JS, pode interagir com scripts e formulários.</td>
          <td style="text-align: left">Mais lento e pesado; consumo de recursos.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Playwright</strong></td>
          <td style="text-align: left">Browser automation / scraping</td>
          <td style="text-align: left">Node.js / Python / .NET</td>
          <td style="text-align: left">Renderização robusta e headless, multi-browser</td>
          <td style="text-align: left">Rápido para automação moderna, suporte multi-engine.</td>
          <td style="text-align: left">Requer gerenciar instâncias de browser; maior complexidade.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Puppeteer / Puppeteer-core</strong></td>
          <td style="text-align: left">Headless Chrome control</td>
          <td style="text-align: left">Node.js</td>
          <td style="text-align: left">Similar ao Playwright, focado Chrome/Chromium</td>
          <td style="text-align: left">Bom para páginas JS; API fluída.</td>
          <td style="text-align: left">Focado no motor Chromium.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Apache Nutch</strong></td>
          <td style="text-align: left">Crawler distribuído / search</td>
          <td style="text-align: left">Java</td>
          <td style="text-align: left">Crawling em larga escala, integração com Hadoop</td>
          <td style="text-align: left">Escalável, extensível; pensado para motores de busca.</td>
          <td style="text-align: left">Mais complexo; stack Java/Hadoop.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Heritrix</strong></td>
          <td style="text-align: left">Crawler para arquivamento</td>
          <td style="text-align: left">Java</td>
          <td style="text-align: left">Arquivamento web (ex.: bibliotecas, instituições)</td>
          <td style="text-align: left">Projetado para arquivamento em larga escala.</td>
          <td style="text-align: left">Complexidade operacional.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Crawlee (Apify SDK)</strong></td>
          <td style="text-align: left">Framework de scraping</td>
          <td style="text-align: left">Node.js</td>
          <td style="text-align: left">Escalabilidade, integração com Apify</td>
          <td style="text-align: left">Bom para jobs em nuvem, rotinas reutilizáveis.</td>
          <td style="text-align: left">Ecossistema mais jovem que Scrapy.</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="5-o-que-são-apis-rest-e-como-funcionam">5. O que são APIs REST e como funcionam<a hidden class="anchor" aria-hidden="true" href="#5-o-que-são-apis-rest-e-como-funcionam">#</a></h2>
<h3 id="conceito">Conceito<a hidden class="anchor" aria-hidden="true" href="#conceito">#</a></h3>
<p><strong>API (Application Programming Interface)</strong> é uma interface que permite que aplicações comuniquem entre si. <strong>REST (Representational State Transfer)</strong> é um estilo arquitetural para APIs sobre HTTP que usa recursos (URLs) e operações HTTP (GET, POST, PUT, DELETE, PATCH) para manipular o estado.</p>
<h3 id="princípios-chave-do-rest">Princípios chave do REST<a hidden class="anchor" aria-hidden="true" href="#princípios-chave-do-rest">#</a></h3>
<ul>
<li><strong>Recursos identificáveis por URIs</strong> (ex.: <code>/users/123</code>).</li>
<li><strong>Operações via métodos HTTP</strong>: <code>GET</code> para leitura, <code>POST</code> para criar, <code>PUT</code>/<code>PATCH</code> para atualizar, <code>DELETE</code> para excluir.</li>
<li><strong>Statelessness:</strong> cada requisição deve conter informação suficiente para o servidor processá-la (não manter estado no servidor entre requisições).</li>
<li><strong>Representação:</strong> os recursos são retornados em formatos padrão (JSON é o mais comum hoje).</li>
<li><strong>HATEOAS (hipermídia como o motor do estado da aplicação)</strong> — ideal REST fulness, mas nem sempre implementado.</li>
</ul>
<h3 id="elementos-práticos">Elementos práticos<a hidden class="anchor" aria-hidden="true" href="#elementos-práticos">#</a></h3>
<ul>
<li><strong>Autenticação/Autorização:</strong> API keys, OAuth 2.0, JWT.</li>
<li><strong>Rate limiting:</strong> para evitar abuso e proteger recursos do servidor.</li>
<li><strong>Versionamento:</strong> <code>/v1/</code> ou versionamento via cabeçalhos.</li>
<li><strong>Códigos de status HTTP:</strong> 200, 201, 204, 400, 401, 403, 404, 429, 500 etc.</li>
</ul>
<h3 id="exemplo-simples-curl">Exemplo simples (curl)<a hidden class="anchor" aria-hidden="true" href="#exemplo-simples-curl">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Requisição GET para obter um recurso</span>
</span></span><span style="display:flex;"><span>curl -X GET <span style="color:#e6db74">&#34;https://api.exemplo.com/v1/users/123&#34;</span> -H <span style="color:#e6db74">&#34;Accept: application/json&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Requisição POST para criar</span>
</span></span><span style="display:flex;"><span>curl -X POST <span style="color:#e6db74">&#34;https://api.exemplo.com/v1/users&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -H <span style="color:#e6db74">&#34;Content-Type: application/json&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -d <span style="color:#e6db74">&#39;{&#34;name&#34;:&#34;Maria&#34;,&#34;email&#34;:&#34;maria@ex.com&#34;}&#39;</span>
</span></span></code></pre></div><hr>
<h2 id="6-apis-públicas-úteis">6. APIs públicas úteis<a hidden class="anchor" aria-hidden="true" href="#6-apis-públicas-úteis">#</a></h2>
<blockquote>
<p>Repositórios e coleções úteis de APIs públicas:</p>
<ul>
<li><strong>Public APIs (GitHub)</strong> — lista colaborativa de APIs gratuitas e públicas.</li>
</ul></blockquote>
<p>Exemplos de APIs públicas que costumam ser úteis em estudos e projetos:</p>
<ul>
<li><strong>GitHub API</strong>: metadados de repositórios, usuários, issues.</li>
<li><strong>OpenStreetMap / Nominatim</strong>: geocodificação e dados cartográficos abertos.</li>
<li><strong>APIs de dados governamentais</strong>: muitos países oferecem portais de dados abertos (open data).</li>
<li><strong>NewsAPI.org</strong>: Fornece artigos de várias fontes jornalísticas internacionais.</li>
<li><strong>Mediastack API</strong>: Similar ao NewsAPI, fornece notícias globais em tempo real.</li>
<li><strong>GNews API</strong>: Focado em notícias recentes, com endpoints simples e suporte a várias línguas.</li>
<li><strong>Portal de Dados Abertos</strong>: Encontre dados publicados pelo governo federal e por governos locais para realizar pesquisas, desenvolver aplicativos e criar novos serviços.</li>
</ul>
<hr>
<h2 id="7-desafios-legais-e-éticos-na-coleta-de-dados">7. Desafios legais e éticos na coleta de dados<a hidden class="anchor" aria-hidden="true" href="#7-desafios-legais-e-éticos-na-coleta-de-dados">#</a></h2>
<h3 id="principais-aspectos-legais">Principais aspectos legais<a hidden class="anchor" aria-hidden="true" href="#principais-aspectos-legais">#</a></h3>
<ul>
<li><strong>Terms of Service (ToS):</strong> muitos sites proíbem scraping em seus termos. Romper ToS pode levar a ações civis ou bloqueios técnicos.</li>
<li><strong>Robots.txt:</strong> não é lei, mas é considerado uma convenção de boa conduta; ignorá-lo aumenta risco reputacional e técnico.</li>
<li><strong>Leis de proteção de dados (ex.: GDPR, LGPD):</strong> coleta de dados pessoais requer bases legais, transparência, e cumprimento de direitos dos titulares.</li>
<li><strong>CFAA e jurisprudência:</strong> em alguns países (ex.: EUA) a legislação sobre acesso não autorizado (CFAA) foi usada em disputas. Um caso famoso é <em>hiQ v. LinkedIn</em>, que envolveu scraping de perfis públicos e gerou decisões e recursos que influenciaram o entendimento jurídico — essa área continua em evolução e depende da jurisdição.</li>
</ul>
<h3 id="questões-éticas">Questões éticas<a hidden class="anchor" aria-hidden="true" href="#questões-éticas">#</a></h3>
<ul>
<li><strong>Privacidade:</strong> mesmo dados “públicos” podem afetar privacidade quando agregados e reidentificados.</li>
<li><strong>Impacto econômico:</strong> crawlers que geram tráfego massivo podem impor custos ao dono do site.</li>
<li><strong>Consentimento e transparência:</strong> ser transparente sobre coleta e uso de dados é prática ética recomendada.</li>
<li><strong>Uso justo e direitos autorais:</strong> reutilizar conteúdo sem autorização para fins comerciais pode infringir direitos.</li>
</ul>
<hr>
<h2 id="8-boas-práticas-ao-coletar-dados-crawling-e-via-apis">8. Boas práticas ao coletar dados (crawling e via APIs)<a hidden class="anchor" aria-hidden="true" href="#8-boas-práticas-ao-coletar-dados-crawling-e-via-apis">#</a></h2>
<ul>
<li><strong>Prefira APIs oficiais</strong> quando existirem.</li>
<li><strong>Respeite <code>robots.txt</code></strong> e políticas do site.</li>
<li><strong>Implemente rate limiting</strong> e backoff exponencial para reduzir carga no servidor.</li>
<li><strong>Use User-Agent claro</strong> e informações de contato (quando apropriado).</li>
<li><strong>Cache e incremental crawling</strong> para evitar downloads redundantes.</li>
<li><strong>Proteja dados pessoais</strong> e cumpra leis de proteção de dados.</li>
<li><strong>Documente seu pipeline</strong> e mantenha logs de acesso para auditoria.</li>
<li><strong>Negocie acesso</strong> com provedores de conteúdo quando for coletar em larga escala (parcerias, contratos).</li>
</ul>
<hr>
<h2 id="9-conclusão">9. Conclusão<a hidden class="anchor" aria-hidden="true" href="#9-conclusão">#</a></h2>
<p>Web crawling e APIs REST são ferramentas poderosas para obter dados da web. Enquanto APIs oferecem acesso estruturado e seguro quando disponíveis, crawlers permitem descobrir conteúdo onde APIs não existem, mas trazem complexidade técnica e riscos legais/éticos.</p>
<p>Adote sempre práticas responsáveis: prefira APIs, seja transparente, e respeite limites técnicos e legais.</p>
<hr>
<h2 id="10-referências">10. Referências<a hidden class="anchor" aria-hidden="true" href="#10-referências">#</a></h2>
<ul>
<li>
<p>Cloudflare — <em>What is a web crawler?</em> — <a href="https://www.cloudflare.com/learning/bots/what-is-a-web-crawler/">https://www.cloudflare.com/learning/bots/what-is-a-web-crawler/</a></p>
</li>
<li>
<p>AWS — <em>What is RESTful API?</em> — <a href="https://aws.amazon.com/what-is/restful-api/">https://aws.amazon.com/what-is/restful-api/</a></p>
</li>
<li>
<p>GitHub — <em>public-apis (lista de APIs públicas)</em> — <a href="https://github.com/public-apis/public-apis">https://github.com/public-apis/public-apis</a></p>
</li>
<li>
<p>ScrapeHero / Apify — comparativos e listas de ferramentas (2024–2025).</p>
<ul>
<li><a href="https://www.scrapehero.com/open-source-web-scraping-frameworks-and-tools/">https://www.scrapehero.com/open-source-web-scraping-frameworks-and-tools/</a></li>
<li><a href="https://blog.apify.com/top-11-open-source-web-crawlers-and-one-powerful-web-scraper/">https://blog.apify.com/top-11-open-source-web-crawlers-and-one-powerful-web-scraper/</a></li>
</ul>
</li>
</ul>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="//localhost:49877/posts/sitesestaticos/">
    <span class="title">« Prev</span>
    <br>
    <span>Estudo: Análise e Uso do Hugo</span>
  </a>
  <a class="next" href="//localhost:49877/posts/arquiteturadeagentesdeia/">
    <span class="title">Next »</span>
    <br>
    <span>Estudo: Arquitetura e Implementação de Agentes de IA</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:49877/">É Fake</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
